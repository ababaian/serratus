{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run: Phase 1 Clean-up - QC hu / mamm / vert\n",
    "\n",
    "```\n",
    "Lead     : ababaian\n",
    "Issue    : \n",
    "Version  : v0.3.3\n",
    "start    : 2020 06 13\n",
    "complete : 2020 06 13\n",
    "files    : ~/serratus/notebook/200612_ab/\n",
    "s3_files : s3://serratus-public/notebook/200612_ab/\n",
    "output   : s3://serratus-public/out/200612_qc/\n",
    "```\n",
    "\n",
    "### Objectives\n",
    "- Clean-up missing entries processed from the first batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize local workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 13 08:53:31 PDT 2020\r\n",
      "f6fff24f9e18a6104d024e1394788f28154fb63f\r\n"
     ]
    }
   ],
   "source": [
    "# Serratus commit version\n",
    "SERRATUS=\"/home/artem/serratus\"\n",
    "cd $SERRATUS\n",
    "\n",
    "# Create local run directory\n",
    "WORK=\"$SERRATUS/notebook/200612_ab\"\n",
    "mkdir -p $WORK; cd $WORK\n",
    "\n",
    "# S3 notebook path\n",
    "S3_WORK='s3://serratus-public/notebook/200612_ab/'\n",
    "\n",
    "# date and version\n",
    "date\n",
    "git rev-parse HEAD # commit version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SRA Accession Initialization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove previously completed accessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2.2 KiB/2.2 KiB with 1 file(s) remaining\r",
      "download: s3://lovelywater2/sra/README.md to ./README.md\r\n"
     ]
    }
   ],
   "source": [
    "cd $WORK\n",
    "\n",
    "# get previous SraRunInfo\n",
    "aws s3 sync s3://lovelywater2/sra/ ./\n",
    "\n",
    "gzip -d *.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   672657 hu_SraRunInfo.csv\r\n",
      "    36104 hu_meta_SraRunInfo.csv\r\n",
      "   100799 mamm_SraRunInfo.csv\r\n",
      "   890747 mu_SraRunInfo.csv\r\n",
      "    94909 vert_SraRunInfo.csv\r\n",
      "    22252 viro2_SraRunInfo.csv\r\n",
      "  1817468 total\r\n",
      " -------------------- \r\n",
      "672657 hu_SraRunInfo.csv\r\n",
      "18740 qc_hu_SraRunInfo.csv\r\n",
      " -------------------- \r\n",
      "36104 hu_meta_SraRunInfo.csv\r\n",
      "395 qc_hu_meta_SraRunInfo.csv\r\n",
      " -------------------- \r\n",
      "100799 mamm_SraRunInfo.csv\r\n",
      "6046 qc_mamm_SraRunInfo.csv\r\n",
      " -------------------- \r\n",
      "890747 mu_SraRunInfo.csv\r\n",
      "617567 qc_mu_SraRunInfo.csv\r\n",
      " -------------------- \r\n",
      "94909 vert_SraRunInfo.csv\r\n",
      "447 qc_vert_SraRunInfo.csv\r\n",
      " -------------------- \r\n",
      "22252 viro2_SraRunInfo.csv\r\n",
      "13392 qc_viro2_SraRunInfo.csv\r\n",
      " -------------------- \r\n",
      "    18740 qc_hu_SraRunInfo.csv\r\n",
      "      395 qc_hu_meta_SraRunInfo.csv\r\n",
      "     6046 qc_mamm_SraRunInfo.csv\r\n",
      "   617567 qc_mu_SraRunInfo.csv\r\n",
      "      447 qc_vert_SraRunInfo.csv\r\n",
      "    13392 qc_viro2_SraRunInfo.csv\r\n",
      "   656587 total\r\n"
     ]
    }
   ],
   "source": [
    "# Create a list of all completed runs to date\n",
    "cd $WORK\n",
    "INDEX=\"v2.sra.complete\" # from last notebook\n",
    "\n",
    "wc -l *.csv\n",
    "\n",
    "echo \" -------------------- \"\n",
    "\n",
    "for SRA in $(ls *.csv)\n",
    "do\n",
    "  # Inverse look-up completed SRA\n",
    "  # into a new SraRunInfo file\n",
    "  grep -vif $INDEX $SRA > \"qc_\"$SRA\n",
    "  \n",
    "  wc -l $SRA\n",
    "  wc -l \"qc_\"$SRA\n",
    "  echo \" -------------------- \"\n",
    "  \n",
    "done\n",
    "\n",
    "wc -l qc*csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the viro2 qc is complete, there were ~320 libraries\n",
    "# that remained unfinished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25625 qc_SraRunInfo.csv\r\n",
      "6ee3bf51717de86475aa9c6e6be61fd7  qc_SraRunInfo.csv\r\n"
     ]
    }
   ],
   "source": [
    "# Merge all un-finished libraries into one qc file\n",
    "# exclude mouse (those will be for 1M push)\n",
    "\n",
    "head -n1  qc_hu_SraRunInfo.csv      >  sra.header.tmp\n",
    "\n",
    "tail -n+2 qc_hu_SraRunInfo.csv      >  qc_SraRunInfo.tmp\n",
    "tail -n+2 qc_hu_meta_SraRunInfo.csv >> qc_SraRunInfo.tmp\n",
    "tail -n+2 qc_mamm_SraRunInfo.csv    >> qc_SraRunInfo.tmp\n",
    "tail -n+2 qc_vert_SraRunInfo.csv    >> qc_SraRunInfo.tmp\n",
    "\n",
    "# shuf and merge\n",
    "shuf qc_SraRunInfo.tmp | cat sra.header.tmp - > qc_SraRunInfo.csv\n",
    "\n",
    "# summary\n",
    "wc -l  qc_SraRunInfo.csv\n",
    "md5sum qc_SraRunInfo.csv\n",
    "\n",
    "\n",
    "mv qc_SraRunInfo.csv tmp_SraRunInfo.csv\n",
    "rm qc_*\n",
    "mv tmp_SraRunInfo.csv qc_SraRunInfo.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terraform Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff --git a/terraform/main/main.tf b/terraform/main/main.tf\r\n",
      "index c030eb5..a0a9134 100644\r\n",
      "--- a/terraform/main/main.tf\r\n",
      "+++ b/terraform/main/main.tf\r\n",
      "@@ -89,10 +89,10 @@ module \"scheduler\" {\r\n",
      "   \r\n",
      "   security_group_ids = [aws_security_group.internal.id]\r\n",
      "   key_name           = var.key_name\r\n",
      "-  instance_type      = \"c5.2xlarge\"\r\n",
      "+  instance_type      = \"c5.4xlarge\"\r\n",
      "   dockerhub_account  = var.dockerhub_account\r\n",
      "   scheduler_port     = var.scheduler_port\r\n",
      "-  flask_workers      = 17 # (2*CPU)+1, according to https://medium.com/building-the-system/gunicorn-3-means-of-concurrency-efbb547674b7\r\n",
      "+  flask_workers      = 31 # (2*CPU)+1, according to https://medium.com/building-the-system/gunicorn-3-means-of-concurrency-efbb547674b7\r\n",
      " }\r\n",
      " \r\n",
      " // Cluster monitor\r\n",
      "@@ -117,7 +117,7 @@ module \"download\" {\r\n",
      "   security_group_ids = [aws_security_group.internal.id]\r\n",
      " \r\n",
      "   instance_type      = \"r5.xlarge\" // Mitigate the memory leak in fastq-dump\r\n",
      "-  volume_size        = 200 // Mitigate the storage leak in fastq-dump\r\n",
      "+  volume_size        = 250 // Mitigate the storage leak in fastq-dump\r\n",
      "   spot_price         = 0.10\r\n",
      " \r\n",
      "   s3_bucket          = module.work_bucket.name\r\n",
      "@@ -159,9 +159,11 @@ module \"merge\" {\r\n",
      "   dev_cidrs          = var.dev_cidrs\r\n",
      "   security_group_ids = [aws_security_group.internal.id]\r\n",
      "   instance_type      = \"c5.large\"\r\n",
      "-  volume_size        = 200 // prevent disk overflow via samtools sort\r\n",
      "+  volume_size        = 100 // prevent disk overflow via samtools sort\r\n",
      "   spot_price         = 0.05\r\n",
      "   s3_bucket          = module.work_bucket.name\r\n",
      "+  // TODO: Add delete permissions for *-blocks\r\n",
      "+  // to merge as redundant delete of completed data\r\n",
      "   s3_delete_prefix   = \"bam-blocks\"\r\n",
      "   s3_prefix          = \"out\"\r\n",
      "   dockerhub_account  = var.dockerhub_account\r\n",
      "@@ -171,7 +173,7 @@ module \"merge\" {\r\n",
      "   // TODO: the credentials are not properly set-up to\r\n",
      "   //       upload to serratus-public, requires a *Object policy\r\n",
      "   //       on the bucket.\r\n",
      "-  options            = \"-k ${module.work_bucket.name} -b s3://serratus-public/out/200606_hu2\"\r\n",
      "+  options            = \"-k ${module.work_bucket.name} -b s3://serratus-public/out/200612_qc\"\r\n",
      " }\r\n",
      " \r\n",
      " // RESOURCES ##############################\r\n",
      "@@ -202,44 +204,88 @@ resource \"local_file\" \"create_tunnel\" {\r\n",
      "   EOF\r\n",
      " }\r\n",
      " \r\n",
      "-resource \"local_file\" \"dl_set_capacity\" {\r\n",
      "-  filename = \"${path.module}/dl_set_capacity.sh\"\r\n",
      "+resource \"local_file\" \"upload_sra\" {\r\n",
      "+  filename = \"${path.module}/uploadSRA.sh\"\r\n",
      "   file_permission = 0777\r\n",
      "   content = <<-EOF\r\n",
      "     #!/bin/bash\r\n",
      "-    set -eux\r\n",
      "-    export AWS_REGION=${var.aws_region}\r\n",
      "-    aws autoscaling set-desired-capacity \\\r\n",
      "-      --auto-scaling-group-name ${module.download.asg_name} \\\r\n",
      "-      --desired-capacity $1\r\n",
      "-  EOF\r\n",
      "-}\r\n",
      "+    # =====================================\r\n",
      "+    # Serratus - uploadSRA.sh\r\n",
      "+    # =====================================\r\n",
      "+    #\r\n",
      "+    # Usage: \r\n",
      "+    # uploadSRA.sh <sraRunInfo.csv>\r\n",
      "+    #\r\n",
      "+    # script for uploading sraRunInfo.csv\r\n",
      "+    # files into Serratus in chunks and with\r\n",
      "+    # randomization of input to normalize load.\r\n",
      "+    # \r\n",
      "+    set -eu\r\n",
      " \r\n",
      "-resource \"local_file\" \"align_set_capacity\" {\r\n",
      "-  filename = \"${path.module}/align_set_capacity.sh\"\r\n",
      "-  file_permission = 0777\r\n",
      "-  content = <<-EOF\r\n",
      "-    #!/bin/bash\r\n",
      "-    set -eux\r\n",
      "-    export AWS_REGION=${var.aws_region}\r\n",
      "-    aws autoscaling set-desired-capacity \\\r\n",
      "-      --auto-scaling-group-name ${module.align.asg_name} \\\r\n",
      "-      --desired-capacity $1\r\n",
      "+    # Config parameters -----------------------------\r\n",
      "+    # Input SRA file\r\n",
      "+    INPUT_SRA=$1\r\n",
      "+\r\n",
      "+    # Chunk size for uploading\r\n",
      "+    SIZE=10000\r\n",
      "+    # -----------------------------------------------\r\n",
      "+\r\n",
      "+    # Check that sraRunInfo was provided\r\n",
      "+\r\n",
      "+    if [ -z \"$INPUT_SRA\" ]; then\r\n",
      "+        echo \"Usage:\"\r\n",
      "+        echo \"  uploadSRA.sh <sraRunInfo.csv>\"\r\n",
      "+        exit 1\r\n",
      "+    fi\r\n",
      "+\r\n",
      "+    # Sript ==============================================\r\n",
      "+\r\n",
      "+    # Descriptive parsing --------------------------------\r\n",
      "+    # Scheduler DNS: \r\n",
      "+    echo \"Loading SRARunInfo into scheduler \"\r\n",
      "+    echo \"  File: $INPUT_SRA\"\r\n",
      "+    echo \"  date: $(date)\"\r\n",
      "+    echo \"  wc  : $(wc -l $INPUT_SRA)\"\r\n",
      "+    echo \"  md5 : $(md5sum $INPUT_SRA)\"\r\n",
      "+    echo \"\"\r\n",
      "+    echo \"\"\r\n",
      "+\r\n",
      "+    # Extract header from csv input\r\n",
      "+    head -n1 $INPUT_SRA > sra.header.tmp\r\n",
      "+\r\n",
      "+    # Split the input csv file into $SIZE chunks\r\n",
      "+    tail -n+2 $INPUT_SRA | split -d -l $SIZE - tmp.chunk\r\n",
      "+\r\n",
      "+    # Re-header an sraRunInfo file for each chunk\r\n",
      "+    # with randomization of the data order\r\n",
      "+    # and upload to Serratus\r\n",
      "+    for CHUNK in $(ls tmp.chunk*); do\r\n",
      "+\r\n",
      "+      cat  sra.header.tmp > \"$CHUNK\"_sraRunInfo.csv\r\n",
      "+      shuf $CHUNK >> \"$CHUNK\"_sraRunInfo.csv\r\n",
      "+\r\n",
      "+      echo '--------------------------'\r\n",
      "+      echo $CHUNK\r\n",
      "+      wc -l \"$CHUNK\"_sraRunInfo.csv\r\n",
      "+      md5sum \"$CHUNK\"_sraRunInfo.csv\r\n",
      "+      \r\n",
      "+      # Upload to Serratus\r\n",
      "+      # via curl (localhost:8000)\r\n",
      "+      curl -s -X POST -T \"$CHUNK\"_sraRunInfo.csv \\\r\n",
      "+        localhost:8000/jobs/add_sra_run_info/\r\n",
      "+      \r\n",
      "+      # Clean-up\r\n",
      "+      rm $CHUNK \"$CHUNK\"_sraRunInfo.csv\r\n",
      "+    done\r\n",
      "+\r\n",
      "+    rm sra.header.tmp\r\n",
      "+\r\n",
      "+    echo \"\"\r\n",
      "+    echo \"\"\r\n",
      "+    echo \" uploadSRA complete.\"\r\n",
      "   EOF\r\n",
      " }\r\n",
      " \r\n",
      "-resource \"local_file\" \"merge_set_capacity\" {\r\n",
      "-  filename = \"${path.module}/merge_set_capacity.sh\"\r\n",
      "-  file_permission = 0777\r\n",
      "-  content = <<-EOF\r\n",
      "-    #!/bin/bash\r\n",
      "-    set -eux\r\n",
      "-    export AWS_REGION=${var.aws_region}\r\n",
      "-    aws autoscaling set-desired-capacity \\\r\n",
      "-      --auto-scaling-group-name ${module.merge.asg_name} \\\r\n",
      "-      --desired-capacity $1\r\n",
      "-  EOF\r\n",
      "-}\r\n",
      " \r\n",
      " // OUTPUT ##############################\r\n",
      " output \"help\" {\r\n"
     ]
    }
   ],
   "source": [
    "# Terraform customization\n",
    "git diff $SERRATUS/terraform/main/main.tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mInitializing modules...\u001b[0m\r\n",
      "\r\n",
      "\u001b[0m\u001b[1mInitializing the backend...\u001b[0m\r\n",
      "\r\n",
      "\u001b[0m\u001b[1mInitializing provider plugins...\u001b[0m\r\n",
      "\r\n",
      "The following providers do not have any version constraints in configuration,\r\n",
      "so the latest version was installed.\r\n",
      "\r\n",
      "To prevent automatic upgrades to new major versions that may contain breaking\r\n",
      "changes, it is recommended to add version = \"...\" constraints to the\r\n",
      "corresponding provider blocks in configuration, with the constraint strings\r\n",
      "suggested below.\r\n",
      "\r\n",
      "* provider.random: version = \"~> 2.2\"\r\n",
      "\r\n",
      "\u001b[0m\u001b[1m\u001b[32mTerraform has been successfully initialized!\u001b[0m\u001b[32m\u001b[0m\r\n",
      "\u001b[0m\u001b[32m\r\n",
      "You may now begin working with Terraform. Try running \"terraform plan\" to see\r\n",
      "any changes that are required for your infrastructure. All Terraform commands\r\n",
      "should now work.\r\n",
      "\r\n",
      "If you ever set or change modules or backend configuration for Terraform,\r\n",
      "rerun this command to reinitialize your working directory. If you forget, other\r\n",
      "commands will detect it and remind you to do so if necessary.\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.data.aws_region.current: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.data.aws_availability_zones.all: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.data.aws_ami.ecs: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.data.aws_ami.amazon_linux_2: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.data.aws_ami.amazon_linux_2: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.data.aws_availability_zones.all: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.data.aws_availability_zones.all: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.data.aws_region.current: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.data.aws_region.current: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.data.aws_ami.ecs: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.data.aws_ami.amazon_linux_2: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.data.aws_ami.amazon_linux_2: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.data.aws_region.current: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.data.aws_region.current: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.random_password.pg_password: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mlocal_file.upload_sra: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.random_password.pg_password: Creation complete after 0s [id=none]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mlocal_file.upload_sra: Creation complete after 0s [id=db5deb3269742410535713cc6c7c3d53cbb21cfe]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role.role: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_cloudwatch_log_group.g: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_role.instance_role: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_ecs_cluster.c: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1maws_security_group.internal: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_cloudwatch_log_group.g: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_role.task_role: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role.role: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_role.instance_role: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket.work: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_role.task_role: Creation complete after 1s [id=SerratusIamRole-scheduler]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role.role: Creation complete after 1s [id=SerratusIamRole-serratus-dl]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_role.instance_role: Creation complete after 1s [id=SerratusEcsInstanceRole-scheduler]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role.role: Creation complete after 1s [id=SerratusIamRole-serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_cloudwatch_log_group.g: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_role.instance_role: Creation complete after 1s [id=SerratusEcsInstanceRole-monitor]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_role.task_role: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_cloudwatch_log_group.g: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_ecs_cluster.c: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_cloudwatch_log_group.scheduler: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_cloudwatch_log_group.g: Creation complete after 1s [id=serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role_policy.cloudwatch: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_cloudwatch_log_group.g: Creation complete after 1s [id=serratus-monitor]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_instance_profile.profile: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_role.task_role: Creation complete after 1s [id=SerratusIamRole-monitor]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role_policy.cloudwatch: Creation complete after 1s [id=SerratusIamRole-serratus-dl:CloudWatchLogsCreate-serratus-dl]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_instance_profile.profile: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_cloudwatch_log_group.g: Creation complete after 1s [id=serratus-dl]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role_policy.cloudwatch: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_cloudwatch_log_group.scheduler: Creation complete after 1s [id=serratus-scheduler]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_cloudwatch_log_group.g: Creation complete after 1s [id=serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_instance_profile.p: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_instance_profile.profile: Creation complete after 1s [id=profile-serratus-dl]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_role_policy_attachment.instance_attachment: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creation complete after 0s [id=SerratusIamRole-serratus-dl-20200613165337050300000002]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_instance_profile.p: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role_policy.cloudwatch: Creation complete after 1s [id=SerratusIamRole-serratus-align:CloudWatchLogsCreate-serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_role_policy_attachment.instance_attachment: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creation complete after 1s [id=SerratusIamRole-serratus-align-20200613165337369400000003]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role.role: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_instance_profile.profile: Creation complete after 1s [id=profile-serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_iam_role_policy.scheduler: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_role_policy_attachment.instance_attachment: Creation complete after 1s [id=SerratusEcsInstanceRole-scheduler-20200613165337545400000004]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.AdjustAutoScaling: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_instance_profile.p: Creation complete after 1s [id=instance-profile-serratus-scheduler]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.ec2Describe: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_role_policy_attachment.instance_attachment: Creation complete after 0s [id=SerratusEcsInstanceRole-monitor-20200613165338053700000005]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.ec2Terminate: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role.role: Creation complete after 0s [id=SerratusIamRole-serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.AdjustAutoScaling: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_instance_profile.p: Creation complete after 2s [id=instance-profile-serratus-monitor]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.ec2Terminate: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_iam_role_policy.scheduler: Creation complete after 1s [id=SerratusIamRole-scheduler:DescribeInstances-scheduler]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.AdjustAutoScaling: Creation complete after 1s [id=SerratusIamRole-serratus-dl:AdjustAutoScaling-serratus-dl]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.ec2Describe: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_ecs_task_definition.scheduler: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1maws_security_group.internal: Creation complete after 4s [id=sg-0d0a5c6baff9ac46d]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role_policy.cloudwatch: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.ec2Describe: Creation complete after 1s [id=SerratusIamRole-serratus-dl:DescribeEC2Instances-serratus-dl]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role_policy_attachment.attachment: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.ec2Terminate: Creation complete after 1s [id=SerratusIamRole-serratus-dl:TerminateEC2Instances-serratus-dl]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_instance_profile.profile: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.AdjustAutoScaling: Creation complete after 1s [id=SerratusIamRole-serratus-align:AdjustAutoScaling-serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.ec2Terminate: Creation complete after 0s [id=SerratusIamRole-serratus-align:TerminateEC2Instances-serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role_policy.cloudwatch: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_ecs_task_definition.scheduler: Creation complete after 0s [id=scheduler]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.ec2Describe: Creation complete after 0s [id=SerratusIamRole-serratus-align:DescribeEC2Instances-serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.ec2Terminate: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.AdjustAutoScaling: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role_policy.cloudwatch: Creation complete after 1s [id=SerratusIamRole-monitor:CloudwatchGetMetrics]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.ec2Describe: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role_policy_attachment.attachment: Creation complete after 1s [id=SerratusIamRole-monitor-20200613165339242900000006]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role_policy.cloudwatch: Creation complete after 1s [id=SerratusIamRole-serratus-merge:CloudWatchLogsCreate-serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creation complete after 1s [id=SerratusIamRole-serratus-merge-20200613165339654700000007]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.ec2Terminate: Creation complete after 1s [id=SerratusIamRole-serratus-merge:TerminateEC2Instances-serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.AdjustAutoScaling: Creation complete after 1s [id=SerratusIamRole-serratus-merge:AdjustAutoScaling-serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_instance_profile.profile: Creation complete after 1s [id=profile-serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.ec2Describe: Creation complete after 0s [id=SerratusIamRole-serratus-merge:DescribeEC2Instances-serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket.work: Creation complete after 6s [id=tf-serratus-work-20200613165334919200000001]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"bam-blocks\"]: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.full: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"fq-blocks\"]: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"out\"]: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.s3_write: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.s3_write: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.s3_delete[0]: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.s3_delete[0]: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"fq-blocks\"]: Creation complete after 1s [id=tf-serratus-work-20200613165334919200000001:prefix-fq-blocks]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.full: Creation complete after 1s [id=tf-serratus-work-20200613165334919200000001:full]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"bam-blocks\"]: Creation complete after 1s [id=tf-serratus-work-20200613165334919200000001:prefix-bam-blocks]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.s3_write: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"out\"]: Creation complete after 1s [id=tf-serratus-work-20200613165334919200000001:prefix-out]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.s3_write: Creation complete after 1s [id=SerratusIamRole-serratus-dl:S3WriteData-serratus-dl]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.s3_delete[0]: Creation complete after 1s [id=SerratusIamRole-serratus-align:S3DeleteData-serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.s3_delete[0]: Creation complete after 1s [id=SerratusIamRole-serratus-merge:S3DeleteData-serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.s3_write: Creation complete after 1s [id=SerratusIamRole-serratus-merge:S3WriteData-serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.s3_write: Creation complete after 1s [id=SerratusIamRole-serratus-align:S3WriteData-serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_ecs_cluster.c: Still creating... [10s elapsed]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_ecs_cluster.c: Still creating... [10s elapsed]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_ecs_cluster.c: Creation complete after 11s [id=arn:aws:ecs:us-east-1:797308887321:cluster/serratus-scheduler]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_ecs_service.scheduler: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_instance.i: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_ecs_cluster.c: Creation complete after 11s [id=arn:aws:ecs:us-east-1:797308887321:cluster/serratus-monitor]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_ecs_service.scheduler: Creation complete after 1s [id=arn:aws:ecs:us-east-1:797308887321:service/serratus-scheduler]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_instance.i: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_instance.i: Still creating... [10s elapsed]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_instance.i: Still creating... [10s elapsed]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_instance.i: Creation complete after 16s [id=i-0c95263fc8ce56c15]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_eip.sch: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_ecs_task_definition.monitor: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_instance.i: Creation complete after 16s [id=i-05b9aa3715348cd5d]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_eip.monitor: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_ecs_task_definition.monitor: Creation complete after 1s [id=monitor]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_ecs_service.monitor: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_ecs_service.monitor: Creation complete after 1s [id=arn:aws:ecs:us-east-1:797308887321:service/serratus-monitor]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_eip.sch: Creation complete after 3s [id=eipalloc-06f5d9409df40b5b2]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_eip.monitor: Creation complete after 2s [id=eipalloc-03207c4290f092431]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mlocal_file.create_tunnel: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mlocal_file.hosts: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mlocal_file.create_tunnel: Creation complete after 0s [id=d7dab9c678bc23bdf12a7f199ee085748a75dcef]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_launch_configuration.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mlocal_file.hosts: Creation complete after 0s [id=3c8f7ad40b4eb5c219ef9682038b9981ade4d7a3]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_launch_configuration.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_launch_configuration.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_launch_configuration.worker: Creation complete after 2s [id=serratus-merge-2020061316540652110000000c]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_launch_configuration.worker: Creation complete after 2s [id=serratus-align-2020061316540652090000000b]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_autoscaling_group.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_launch_configuration.worker: Creation complete after 2s [id=serratus-dl-2020061316540650900000000a]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_autoscaling_group.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_autoscaling_group.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_autoscaling_group.worker: Creation complete after 2s [id=serratus-merge-2020061316540652110000000c]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_autoscaling_policy.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_autoscaling_group.worker: Creation complete after 2s [id=serratus-align-2020061316540652090000000b]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_autoscaling_policy.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_autoscaling_group.worker: Creation complete after 2s [id=serratus-dl-2020061316540650900000000a]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_autoscaling_policy.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_autoscaling_policy.worker: Creation complete after 1s [id=serratus-merge-2020061316540652110000000c]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_autoscaling_policy.worker: Creation complete after 1s [id=serratus-align-2020061316540652090000000b]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_autoscaling_policy.worker: Creation complete after 1s [id=serratus-dl-2020061316540650900000000a]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1m\u001b[32m\r\n",
      "Apply complete! Resources: 71 added, 0 changed, 0 destroyed.\u001b[0m\r\n",
      "\u001b[0m\u001b[1m\u001b[32m\r\n",
      "Outputs:\r\n",
      "\r\n",
      "align_asg_name = serratus-align-2020061316540652090000000b\r\n",
      "dl_asg_name = serratus-dl-2020061316540650900000000a\r\n",
      "help = Run ./create_tunnels.sh to create SSH tunnels for all services.\r\n",
      "\r\n",
      "merge_asg_name = serratus-merge-2020061316540652110000000c\r\n",
      "monitor_dns = ec2-54-224-136-188.compute-1.amazonaws.com\r\n",
      "scheduler_dns = ec2-54-221-134-195.compute-1.amazonaws.com\r\n",
      "scheduler_pg_password = eCiWKzo67CKkwr1Y\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Initialize terraform\n",
    "TF=$SERRATUS/terraform/main\n",
    "cd $TF\n",
    "terraform init\n",
    "\n",
    "# Launch Terraform Cluster\n",
    "# Initialize the serratus cluster with minimal nodes\n",
    "terraform apply -auto-approve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Serratus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Permanently added 'ec2-54-224-136-188.compute-1.amazonaws.com,54.224.136.188' (ECDSA) to the list of known hosts.\r",
      "\r\n",
      "Warning: Permanently added 'ec2-54-221-134-195.compute-1.amazonaws.com,54.221.134.195' (ECDSA) to the list of known hosts.\r",
      "\r\n",
      "Tunnels created:\r\n",
      "    localhost:3000 = grafana\r\n",
      "    localhost:9090 = prometheus\r\n",
      "    localhost:5432 = postgres\r\n",
      "    localhost:8000 = scheduler\r\n"
     ]
    }
   ],
   "source": [
    "cd $TF\n",
    "\n",
    "# Open SSH tunnels to the monitor\n",
    "./create_tunnels.sh\n",
    "\n",
    "# If you get an error on port\n",
    "# run:\n",
    "# ps aux | grep ssh\n",
    "# sudo kill <PID of SSH>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/artem/serratus/notebook/200612_ab/qc_SraRunInfo.csv\r\n",
      "25625 /home/artem/serratus/notebook/200612_ab/qc_SraRunInfo.csv\r\n"
     ]
    }
   ],
   "source": [
    "# Confirm the upload file\n",
    "BATCH_SRA=$WORK/qc_SraRunInfo.csv\n",
    "echo  $BATCH_SRA\n",
    "wc -l $BATCH_SRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SRARunInfo into scheduler \r\n",
      "  File: /home/artem/serratus/notebook/200612_ab/qc_SraRunInfo.csv\r\n",
      "  date: Sat Jun 13 09:58:34 PDT 2020\r\n",
      "  wc  : 25625 /home/artem/serratus/notebook/200612_ab/qc_SraRunInfo.csv\r\n",
      "  md5 : 6ee3bf51717de86475aa9c6e6be61fd7  /home/artem/serratus/notebook/200612_ab/qc_SraRunInfo.csv\r\n",
      "\r\n",
      "\r\n",
      "--------------------------\r\n",
      "tmp.chunk00\r\n",
      "10001 tmp.chunk00_sraRunInfo.csv\r\n",
      "ac43c0e732e3fd11dfab862a2555538e  tmp.chunk00_sraRunInfo.csv\r\n",
      "{\"inserted_rows\":9998,\"total_rows\":9998}\r\n",
      "--------------------------\r\n",
      "tmp.chunk01\r\n",
      "10001 tmp.chunk01_sraRunInfo.csv\r\n",
      "556cb74cc6b5c024879e4a63298c0767  tmp.chunk01_sraRunInfo.csv\r\n",
      "{\"inserted_rows\":9999,\"total_rows\":19997}\r\n",
      "--------------------------\r\n",
      "tmp.chunk02\r\n",
      "5625 tmp.chunk02_sraRunInfo.csv\r\n",
      "4c9d3fb6bdc335898c7f214ad2812b7e  tmp.chunk02_sraRunInfo.csv\r\n",
      "{\"inserted_rows\":5623,\"total_rows\":25620}\r\n",
      "\r\n",
      "\r\n",
      " uploadSRA complete.\r\n"
     ]
    }
   ],
   "source": [
    "# Upload SraRunInfo.csv into Serratus\n",
    "cd $TF\n",
    "./uploadSRA.sh $BATCH_SRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Serratus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Cluster Config File: \r\n",
      "{\r\n",
      "  \"ALIGN_ARGS\": \"--very-sensitive-local\",\r\n",
      "  \"ALIGN_MAX_INCREASE\": 25,\r\n",
      "  \"ALIGN_SCALING_CONSTANT\": 0.0215,\r\n",
      "  \"ALIGN_SCALING_ENABLE\": true,\r\n",
      "  \"ALIGN_SCALING_MAX\": 1400,\r\n",
      "  \"CLEAR_INTERVAL\": 600,\r\n",
      "  \"DL_ARGS\": \"\",\r\n",
      "  \"DL_MAX_INCREASE\": 10,\r\n",
      "  \"DL_SCALING_CONSTANT\": 0.1,\r\n",
      "  \"DL_SCALING_ENABLE\": true,\r\n",
      "  \"DL_SCALING_MAX\": 400,\r\n",
      "  \"GENOME\": \"cov3ma\",\r\n",
      "  \"MERGE_ARGS\": \"\",\r\n",
      "  \"MERGE_MAX_INCREASE\": 10,\r\n",
      "  \"MERGE_SCALING_CONSTANT\": 0.1,\r\n",
      "  \"MERGE_SCALING_ENABLE\": true,\r\n",
      "  \"MERGE_SCALING_MAX\": 75,\r\n",
      "  \"SCALING_INTERVAL\": 120,\r\n",
      "  \"VIRTUAL_SCALING_INTERVAL\": 45\r\n",
      "}\r\n",
      "\r\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0{\"ALIGN_ARGS\":\"--very-sensitive-local\",\"ALIGN_MAX_INCREASE\":25,\"ALIGN_SCALING_CONSTANT\":0.0215,\"ALIGN_SCALING_ENABLE\":true,\"ALIGN_SCALING_MAX\":1400,\"CLEAR_INTERVAL\":600,\"DL_ARGS\":\"\",\"DL_MAX_INCREASE\":10,\"DL_SCALING_CONSTANT\":0.1,\"DL_SCALING_ENABLE\":true,\"DL_SCALING_MAX\":400,\"GENOME\":\"cov3ma\",\"MERGE_ARGS\":\"\",\"MERGE_MAX_INCREASE\":10,\"MERGE_SCALING_CONSTANT\":0.1,\"MERGE_SCALING_ENABLE\":true,\"MERGE_SCALING_MAX\":75,\"SCALING_INTERVAL\":120,\"VIRTUAL_SCALING_INTERVAL\":45}\r\n",
      "\r",
      "100  1010  100   467  100   543   1033   1201 --:--:-- --:--:-- --:--:--  2234\r\n"
     ]
    }
   ],
   "source": [
    "# Set Cluster Parameters =============================\n",
    "## get Config File (if it doesn't exist)\n",
    "# curl localhost:8000/config | jq > serratus-config.json\n",
    "#\n",
    "cd $TF\n",
    "# Make local changes to config file\n",
    "echo \"  Cluster Config File: \"\n",
    "cat serratus-config.json\n",
    "echo \"\"\n",
    "echo \"\"\n",
    "# Re-upload config file\n",
    "curl -T serratus-config.json localhost:8000/config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stop postgres if it's running \n",
    "# systemctl stop postgresql\n",
    "\n",
    "## Connect to postgres\n",
    "# psql -h localhost postgres postgres\n",
    "\n",
    "### ACCESSION OPERATIONS\n",
    "## Reset SPLITTING accessions to NEW\n",
    "# UPDATE acc SET state = 'new' WHERE state = 'splitting';\n",
    "\n",
    "## Reset SPLIT_ERR accessions to NEW\n",
    "## (repeated failures can be missing SRA data)\n",
    "# UPDATE acc SET state = 'new' WHERE state = 'split_err';\n",
    "\n",
    "## Reset MERGE_ERR accessions to SPLIT_DONE\n",
    "# UPDATE acc SET state = 'split_done' WHERE state = 'merge_err';\n",
    "\n",
    "## Clear DONE Accessions (ONLY ON COMPLETION)\n",
    "# DELETE FROM acc WHERE state = 'merge_done';\n",
    "\n",
    "### BLOCK OPERATIONS\n",
    "\n",
    "##  Reset FAIL blocks to NEW\n",
    "# UPDATE blocks SET state = 'new' WHERE state = 'fail';\n",
    "\n",
    "# Reset ALIGNING blocks to NEW\n",
    "# UPDATE blocks SET state = 'new' WHERE state = 'aligning';\n",
    "\n",
    "# Clear DONE blocks\n",
    "# DELETE FROM blocks WHERE state = 'done';\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "\n",
    "`19508` are so \"persistent errors\" or unavailable files. Completed "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
