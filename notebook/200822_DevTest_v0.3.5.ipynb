{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run: Development Testing v0.3.5\n",
    "\n",
    "```\n",
    "Lead     : ababaian\n",
    "Issue    : \n",
    "Version  : v0.3.5-dev : ab-dev branch\n",
    "start    : 2020 08 22\n",
    "complete : 2020 08 28\n",
    "files    : ~/serratus/notebook/200822_ab/\n",
    "s3_files : s3://serratus-public/notebook/200822_ab/\n",
    "output   : s3://serratus-public/out/200822_dev/\n",
    "```\n",
    "\n",
    "### Intro/Objectives\n",
    "\n",
    "- Development testing to finish diamond / bowtie2 integration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch EC2 Builder (C5.xlarge)\n",
    "# Start docker service on amazon linux 2\n",
    "sudo yum install -y docker\n",
    "sudo yum install -y git\n",
    "sudo service docker start\n",
    "\n",
    "# Download latest serratus repo\n",
    "git clone https://github.com/ababaian/serratus.git -b diamond-dev\n",
    "cd serratus/containers\n",
    "\n",
    "# If you want to upload containers to your repository, include this.\n",
    "export DOCKERHUB_USER='serratusbio' # optional\n",
    "sudo docker login # optional\n",
    "\n",
    "# Build all containers and upload them docker hub repo (if available)\n",
    "./build_containers.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo docker run --rm --entrypoint /bin/bash -it serratus-align:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protref4a\n",
    "\n",
    "Pilot protref4 created\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download protref4 from Robert with updates from me (re-arrange DV, add RDev)\n",
    "aws s3 cp s3://serratus-public/sumbler/protref4.fa  ./protref4a.fa \n",
    "aws s3 cp s3://serratus-public/sumbler/protref4.msa ./protref4a.msa \n",
    "\n",
    "# Make diamond index for protref4\n",
    "diamond makedb --in protref4a.fa -d protref4a\n",
    "\n",
    "# Make fasta index for protref4\n",
    "samtools faidx protref4a.fa\n",
    "mv protref4a.fa.fai protref4a.sumzer.tsv\n",
    "\n",
    "md5sum * > protref4a.md5\n",
    "\n",
    "aws s3 sync ./ s3://serratus-public/seq/protref4a/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b849ce4a8ff531e7daf164d01c49551c  protref4a.dmnd\n",
    "# 2da44e7f53fd1126ee34664700313816  protref4a.fa\n",
    "# 34ecc814018b826c2b111c407539997d  protref4a.msa\n",
    "# 3483690c5e0c92d9a08109453ec5258d  protref4a.sumzer.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protref4b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download protref4 from Robert with updates from me (re-arrange DV, add RDev)\n",
    "aws s3 cp s3://serratus-public/seq/protref4b/protref4b.fa  ./\n",
    "aws s3 cp s3://serratus-public/seq/protref4b/protref4b.msa ./ \n",
    "\n",
    "# Make diamond index for protref4\n",
    "diamond makedb --in protref4b.fa -d protref4b\n",
    "\n",
    "# Make fasta index for protref4\n",
    "samtools faidx protref4b.fa\n",
    "mv protref4b.fa.fai protref4b.sumzer.tsv\n",
    "\n",
    "md5sum * > protref4b.md5\n",
    "\n",
    "aws s3 sync ./ s3://serratus-public/seq/protref4b/\n",
    "\n",
    "# fed5309d58d1eeb1711878ce2e9e9170  protref4b.dmnd\n",
    "# b978fc1fc3180affaaf40de7b05d4aab  protref4b.fa\n",
    "# e094fc7db19c07ffcedf8bc42963ab80  protref4b.msa\n",
    "# 2dfa9417d40fbbc882c433baef77f592  protref4b.sumzer.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protref5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download protref4 from Robert with updates from me (re-arrange DV, add RDev)\n",
    "aws s3 sync s3://serratus-public/rce/protref_v5/ ./\n",
    "\n",
    "mv protref_v5.fa protref5.fa\n",
    "mv otus_final.muscle.afa protref5.msa\n",
    "mv protref_v5_famcounts.tsv protref5.fam.tsv\n",
    "\n",
    "\n",
    "# Make diamond index for protref5\n",
    "diamond makedb --in protref5.fa -d protref5\n",
    "\n",
    "# Make fasta index for protref5\n",
    "samtools faidx protref5.fa\n",
    "mv protref5.fa.fai protref5.sumzer.tsv\n",
    "\n",
    "md5sum * > protref5.md5\n",
    "\n",
    "aws s3 sync ./ s3://serratus-public/seq/protref5/\n",
    "\n",
    "# 8b3e3c63dc12fa4837448c2662363c2d  protref5.dmnd\n",
    "# 9891b06413224a1cfc79b27070ad4498  protref5.fa\n",
    "# 408665b7c01de9739936860b214577c7  protref5.fam.tsv\n",
    "# e094fc7db19c07ffcedf8bc42963ab80  protref5.msa\n",
    "# a996ba01f5b4de8606b632122ebb4c92  protref5.sumzer.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicistroviridae Sequences\n",
    "\n",
    "Adding a set of dicistroviridae sequences\n",
    "\n",
    "#### SRA Nucleotide Query\n",
    "\n",
    "Query: `txid232795[Organism:exp]`\n",
    "Date : `2020-08-23`\n",
    "Results: `2871`\n",
    "\n",
    "Saved to \"s3://serratus-public/seq/protref4a/dicistro_all.fa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce Dicistro sequences\n",
    "# Load serratus-align container on EC2\n",
    "sudo docker run --rm --entrypoint /bin/bash \\\n",
    "  -it serratus-align:latest\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Dev tools\n",
    "yum install -y wget tar gzip less vim unzip\n",
    "\n",
    "# SeqKit Install\n",
    "wget https://github.com/shenwei356/seqkit/releases/download/v0.12.0/seqkit_linux_amd64.tar.gz &&\\\n",
    "  tar -xvf seqkit* && mv seqkit /usr/local/bin/ &&\\\n",
    "  rm seqkit_linux*\n",
    "  \n",
    "# local bedtools install\n",
    "wget https://github.com/arq5x/bedtools2/releases/download/v2.29.2/bedtools.static.binary\n",
    "mv bedtools.static.binary bedtools\n",
    "chmod 755 bedtools; mv bedtools /usr/bin/\n",
    "\n",
    "# Local usearch install\n",
    "#The clustered database was made with usearch:\n",
    "\n",
    "wget https://drive5.com/downloads/usearch11.0.667_i86linux32.gz\n",
    "gzip -dc usearch11.0.667_i86linux32.gz > usearch\n",
    "chmod 755 usearch; mv usearch /usr/bin/usearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBOSS Installation\n",
    "yum install gcc-c++ gsl gsl-devel make\n",
    "\n",
    "# EMBOSS Tools\n",
    "wget ftp://emboss.open-bio.org/pub/EMBOSS/EMBOSS-6.6.0.tar.gz\n",
    "tar -xvf EMBOSS-6.6.0.tar.gz\n",
    "cd EMBOSS-6.6.0/\n",
    "./configure --without-x && make && make install\n",
    "cp emboss/msbar /usr/bin/\n",
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p dicis; cd dicis\n",
    "\n",
    "aws s3 cp s3://serratus-public/seq/protref4a/dicistro_all.fa ./\n",
    "aws s3 cp s3://serratus-public/seq/protref4a/dicistro_refseq.fa ./\n",
    "\n",
    "cat dicistro_refseq.fa dicistro_all.fa > dicistro.fa\n",
    "\n",
    "# Create a header file to store original seq file\n",
    "NAME='dicistro'\n",
    "grep \"^>\" $NAME.fa > $NAME.headers\n",
    "gzip $NAME.headers\n",
    "\n",
    "# Ancient virus: KJ938718.1 added manually\n",
    "# to ancient.fa\n",
    "\n",
    "# Remove duplicate and short sequences\n",
    "# 638\n",
    "seqkit rmdup -s -i -D $NAME.dup $NAME.fa > $NAME.rmdup.fa\n",
    "\n",
    "# Remove Accessions shorter than 6000 nt\n",
    "seqkit seq -m 6000 $NAME.rmdup.fa > $NAME.gt6k.rmdup.fa\n",
    "\n",
    "# Prune to 95% nucleotide identity\n",
    "usearch -cluster_smallmem $NAME.gt6k.rmdup.fa \\\n",
    "   -id 0.95 \\\n",
    "   -sortedby other \\\n",
    "   -maxaccepts 4 \\\n",
    "   -maxrejects 64 \\\n",
    "   -maxhits 1 \\\n",
    "   -uc $NAME.id95.uc \\\n",
    "   -centroids $NAME.id95.fa\n",
    "   \n",
    "grep \"^>\" $NAME.id95.fa > $NAME.id95.headers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ORFs\n",
    "getorf -sequence $NAME.id95.fa \\\n",
    "  -find 1 \\\n",
    "  -minsize 1000 -reverse N \\\n",
    "  -outseq $NAME.orf.fa\n",
    "  \n",
    "getorf -sequence ancient.fa \\\n",
    "  -find 0 \\\n",
    "  -minsize 400 -reverse N \\\n",
    "  -outseq ancient.orf.fa  \n",
    "# Named ORF1 and ORF2 KJ938718.1\n",
    "\n",
    "# Sort\n",
    "#usearch -sortbylength $NAME.orf.fa \\\n",
    "#   -fastaout $NAME.orf.sort.fa\n",
    "   \n",
    "# Prune to 95% nucleotide identity\n",
    "usearch -cluster_smallmem $NAME.orf.fa \\\n",
    "   -id 0.95 \\\n",
    "   -sortedby other \\\n",
    "   -maxaccepts 4 \\\n",
    "   -maxrejects 64 \\\n",
    "   -maxhits 1 \\\n",
    "   -uc $NAME.orf.id95.uc \\\n",
    "   -centroids $NAME.orf.id95.fa\n",
    "\n",
    "# Seqkit sort\n",
    "seqkit sort -n $NAME.orf.id95.fa \\\n",
    "  > $NAME.orf.id95.sort.fa\n",
    "\n",
    "# re-header\n",
    "#>Coronaviridae.RdRp.NC_038294\n",
    "sed 's/ \\[.*//g' $NAME.orf.id95.sort.fa \\\n",
    "  | sed 's/>\\(.*\\)_\\([0-9]\\)\\($\\)/>Dicistroviridae.ORF\\2.\\1/g' - \\\n",
    "  > $NAME.ref.fa\n",
    "  \n",
    "grep \"^>\" $NAME.orf.id95.sort.fa ancient.orf.fa > $NAME.protref.headers\n",
    "gzip $NAME.protref.headers\n",
    "\n",
    "cat dicistro.ref.fa ancient.orf.fa > dicistro.protref.fa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws s3 sync ./ s3://serratus-public/notebook/200822_ab/dicistro/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quenyaviridae Sequences\n",
    "\n",
    "From [Obbard et al](https://academic.oup.com/ve/article/6/1/vez061/5708932)\n",
    "\n",
    "Downloaded via nuccore `2020 08 28`\n",
    "\n",
    "```\n",
    "# Segment 1\n",
    "KY634871 OR KY634875 OR MN264686 OR MN264681 OR MN371240 OR MN371238 OR MN371244 OR MN371247 OR MN371231\n",
    "# Segment 1 TSA\n",
    "GBQS01013140 OR GASG02022301 OR GAUJ01047315 OR GBOS01033164\n",
    "# Segment 2\n",
    "KY634872 OR KY634876 OR MN264687 OR MN264682\n",
    "# Segment 3\n",
    "KY634873 OR KY634877 OR MN264688 OR MN264683\n",
    "# Segment 4\n",
    "MN264684 OR MN371232 \n",
    "# Segment 5\n",
    "MH937728 OR MH937729 OR MN264690 OR MN264685 OR MN371233 OR MN371241 OR MN371239 OR MN371245 OR MN371248 OR MN371234 OR MN371235 OR MN371236 OR MN371237 OR MN371243 OR MN371242 OR MN371246 OR MN371249 OR MN371250 OR MN371251 OR MN371252 OR MN371253 OR MN371254\n",
    "# Segment 5 (RdRp)\n",
    "GBKE01003710 OR GDIO01031530 OR GEDC01030233 OR GEDC01010646 OR GBVD01020893 OR GBBI01004385 OR GCDX01009922 OR GDDR01018688 OR GDES01014899 OR GCZF01072004 OR GHOY01071622 OR GGPH01203597 OR GHJE01057056 OR GAUC01011130 OR GAVW02027760 OR GCPB01083611 OR GBVI01014741 OR GFJU01178533 OR GBWM01032350 OR HAGY01027881\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p quenya; cd quenya\n",
    "\n",
    "# Create a header file to store original seq file\n",
    "NAME='quenya'\n",
    "grep \"^>\" *.fasta > $NAME.headers\n",
    "gzip $NAME.headers\n",
    "\n",
    "aws s3 sync s3://serratus-public/notebook/200822_ab/quenya/ ./\n",
    "rm -rf vez061*\n",
    "rm queries.txt\n",
    "\n",
    "# quenya1.fa\n",
    "# quenya1_tsa.fa\n",
    "# quenya2.fa\n",
    "# quenya3.fa\n",
    "# quenya4.fa\n",
    "# quenya5.fa\n",
    "# quenya5_tsa.fa\n",
    "\n",
    "# Get ORFs\n",
    "function qorf {\n",
    "getorf -sequence $1.fasta \\\n",
    "  -find 1 \\\n",
    "  -minsize 1000 -reverse N \\\n",
    "  -outseq $1.orf.fa\n",
    "  \n",
    "sed 's/ \\[.*//g' $1.orf.fa \\\n",
    "  | sed \"s/>\\(.*\\)_\\([0-9]\\)\\($\\)/>Quenyaviridae.$2.\\1/g\" - \\\n",
    "  >> quenya.ref.fa  \n",
    "}\n",
    "\n",
    "qorf quenya1 orf1\n",
    "qorf quenya2 orf2\n",
    "qorf quenya3 orf3\n",
    "qorf quenya4 orf4\n",
    "qorf quenya5 rdrp\n",
    "\n",
    "# GetORF from TSA\n",
    "getorf -sequence quenya1_tsa.fasta \\\n",
    "  -find 1 \\\n",
    "  -minsize 300\\\n",
    "  -outseq quenya1_tsa.orf.fa\n",
    "  \n",
    "sed 's/ \\[.*//g' quenya1_tsa.orf.fa \\\n",
    "  | sed \"s/>\\(.*\\)_\\([0-9]\\)\\($\\)/>Quenyaviridae.orf1.\\1/g\" - \\\n",
    "  >> quenya.tsa.fa\n",
    "\n",
    "# GetORF from TSA\n",
    "getorf -sequence quenya5_tsa.fasta \\\n",
    "  -find 1 \\\n",
    "  -minsize 300 \\\n",
    "  -outseq quenya5_tsa.orf.fa\n",
    "  \n",
    "sed 's/ \\[.*//g' quenya5_tsa.orf.fa \\\n",
    "  | sed \"s/>\\(.*\\)_\\([0-9]\\)\\($\\)/>Quenyaviridae.rdrp.\\1/g\" - \\\n",
    "  >> quenya.tsa.fa\n",
    "\n",
    "# Merge genbank + tsa\n",
    "cat quenya.ref.fa quenya.tsa.fa  > quenya.reftsa.fa\n",
    "\n",
    "\n",
    "NAME='quenya'\n",
    "# Prune to 95% nucleotide identity\n",
    "usearch -cluster_smallmem $NAME.reftsa.fa \\\n",
    "   -id 0.95 \\\n",
    "   -sortedby other \\\n",
    "   -maxaccepts 4 \\\n",
    "   -maxrejects 64 \\\n",
    "   -maxhits 1 \\\n",
    "   -uc $NAME.id95.uc \\\n",
    "   -centroids $NAME.id95.fa\n",
    "\n",
    "mv quenya.id95.fa quenya.protref.fa\n",
    "\n",
    "md5sum * > quenya.md5\n",
    "\n",
    "aws s3 sync  ./ s3://serratus-public/notebook/200822_ab/quenya/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protref5 with quenya update v200828\n",
    "\n",
    "# Download protref4 from Robert with updates from me (re-arrange DV, add RDev)\n",
    "aws s3 sync s3://serratus-public/rce/protref_v5/ ./\n",
    "aws s3 cp s3://serratus-public/notebook/200822_ab/quenya/quenya.protref.fa ./\n",
    "\n",
    "cat protref_v5.fa quenya.protref.fa > protref5.fa\n",
    "rm protref_v5.fa quenya.protref.fa\n",
    "\n",
    "mv otus_final.muscle.afa protref5.msa\n",
    "mv protref_v5_famcounts.tsv protref5.fam.tsv\n",
    "\n",
    "\n",
    "# Make diamond index for protref5\n",
    "diamond makedb --in protref5.fa -d protref5\n",
    "\n",
    "# Make fasta index for protref5\n",
    "samtools faidx protref5.fa\n",
    "mv protref5.fa.fai protref5.sumzer.tsv\n",
    "\n",
    "md5sum * > protref5.md5\n",
    "\n",
    "aws s3 sync ./ s3://serratus-public/seq/protref5/\n",
    "\n",
    "# a89e5190810e309a253ff4d8329b49a6  protref5.dmnd\n",
    "# 3164cbd0e40b20f32cdd9ca27483492d  protref5.fa\n",
    "# 408665b7c01de9739936860b214577c7  protref5.fam.tsv\n",
    "# e094fc7db19c07ffcedf8bc42963ab80  protref5.msa\n",
    "# fe5d52d6af78ed40c92dcea793a5ca42  protref5.sumzer.tsv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### crASS and Double Jelly Phages\n",
    "\n",
    "From Anton K:\n",
    "\n",
    "```\n",
    "1. TerL.fa ~@~S protein set of TerL (large terminase subunit) of crAss-like phage group.\n",
    "From https://www.biorxiv.org/content/10.1101/2020.07.20.212944v1.full.pdf\n",
    "Publicly available from ftp://ftp.ncbi.nih.gov/pub/yutinn/crassfamily_2020/\n",
    "2. MCP.fa ~@~S protein set of Double Jelly-Roll major capsid proteins (DJR MCP)\n",
    "From https://pubmed.ncbi.nlm.nih.gov/29636073/\n",
    "Publicly available from ftp://ftp.ncbi.nih.gov/pub/yutinn/DJR_MCP_2017/\n",
    "```\n",
    "\n",
    "Manually updated names of each entry with accessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protref5 with phage2 update v200829\n",
    "\n",
    "# Download protref4 from Robert with updates from me (re-arrange DV, add RDev)\n",
    "aws s3 sync s3://serratus-public/rce/protref_v5/ ./\n",
    "aws s3 cp s3://serratus-public/notebook/200822_ab/quenya/quenya.protref.fa ./\n",
    "aws s3 cp s3://serratus-public/notebook/200830_ak/Koonin_phages/DRJ.sortref.fa ./\n",
    "aws s3 cp s3://serratus-public/notebook/200830_ak/Koonin_phages/crass.sortref.fa ./\n",
    "\n",
    "cat protref_v5.fa \\\n",
    "  quenya.protref.fa \\\n",
    "  DRJ.sortref.fa \\\n",
    "  crass.sortref.fa \\\n",
    "  > protref5.fa\n",
    "  \n",
    "rm protref_v5.fa quenya.protref.fa DRJ.sortref.fa crass.sortref.fa\n",
    "\n",
    "mv otus_final.muscle.afa protref5.msa\n",
    "mv protref_v5_famcounts.tsv protref5.fam.tsv\n",
    "\n",
    "\n",
    "# Make diamond index for protref5\n",
    "diamond makedb --in protref5.fa -d protref5\n",
    "\n",
    "# Make fasta index for protref5\n",
    "samtools faidx protref5.fa\n",
    "mv protref5.fa.fai protref5.sumzer.tsv\n",
    "\n",
    "md5sum * > protref5.md5\n",
    "\n",
    "aws s3 sync ./ s3://serratus-public/seq/protref5/\n",
    "\n",
    "#7bb49127fa13c5df69f5ab57a60ae644  protref5.dmnd\n",
    "#f99c75b070d8f7f915976fa4587d7195  protref5.fa\n",
    "#408665b7c01de9739936860b214577c7  protref5.fam.tsv\n",
    "#e094fc7db19c07ffcedf8bc42963ab80  protref5.msa\n",
    "#fbd749480a96c9f10ecb29dc9f1ceb8b  protref5.sumzer.tsv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Development Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize local workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug 30 10:19:38 PDT 2020\r\n",
      "3af0bc63b69402671f33246f2b05a265e448692b\r\n"
     ]
    }
   ],
   "source": [
    "# Serratus commit version\n",
    "SERRATUS=\"/home/artem/serratus\"\n",
    "cd $SERRATUS\n",
    "\n",
    "# Create local run directory\n",
    "WORK=\"$SERRATUS/notebook/200822_ab\"\n",
    "mkdir -p $WORK; cd $WORK\n",
    "\n",
    "# S3 notebook path\n",
    "S3_WORK='s3://serratus-public/notebook/200822_ab/'\n",
    "\n",
    "# date and version\n",
    "date\n",
    "git rev-parse HEAD # commit version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SRA Accession Initialize\n",
    "cd $WORK\n",
    "BATCH='test_SraRunInfo.csv'\n",
    "\n",
    "aws s3 cp s3://lovelywater2/sra/viro_SraRunInfo.csv.gz ./\n",
    "gzip -d *\n",
    "\n",
    "head -n1 viro_SraRunInfo.csv > header\n",
    "\n",
    "shuf viro_SraRunInfo.csv | head -n 20 > test_runs\n",
    "\n",
    "cat header test_runs > $BATCH\n",
    "\n",
    "rm viro_SraRunInfo.csv header test_runs viro_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 256.0 KiB/1.9 MiB with 1 file(s) remaining\r",
      "Completed 512.0 KiB/1.9 MiB with 1 file(s) remaining\r",
      "Completed 768.0 KiB/1.9 MiB with 1 file(s) remaining\r",
      "Completed 1.0 MiB/1.9 MiB with 1 file(s) remaining  \r",
      "Completed 1.2 MiB/1.9 MiB with 1 file(s) remaining  \r",
      "Completed 1.5 MiB/1.9 MiB with 1 file(s) remaining  \r",
      "Completed 1.8 MiB/1.9 MiB with 1 file(s) remaining  \r",
      "Completed 1.9 MiB/1.9 MiB with 1 file(s) remaining  \r",
      "download: s3://lovelywater2/sra/viro_SraRunInfo.csv.gz to ./viro_SraRunInfo.csv.gz\r\n",
      "shuf: write error: Broken pipe\r\n",
      "shuf: write error\r\n",
      "rm: cannot remove 'viro_SraRunInfo.csv': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "# SRA Accession Initialize\n",
    "cd $WORK\n",
    "BATCH='test2_SraRunInfo.csv'\n",
    "\n",
    "aws s3 cp s3://lovelywater2/sra/viro_SraRunInfo.csv.gz ./\n",
    "gzip -d *.gz\n",
    "\n",
    "head -n1 viro_SraRunInfo.csv > header\n",
    "\n",
    "shuf viro_SraRunInfo.csv | head -n 1000 > test_runs\n",
    "\n",
    "cat header test_runs > $BATCH\n",
    "\n",
    "rm viro_SraRunInfo.csv header test_runs viro_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SRA Accession Initialize\n",
    "cd $WORK\n",
    "BATCH='test3_SraRunInfo.csv'\n",
    "\n",
    "aws s3 cp s3://lovelywater2/sra/viro_SraRunInfo.csv.gz ./\n",
    "gzip -d *.gz\n",
    "\n",
    "head -n1 viro_SraRunInfo.csv > header\n",
    "\n",
    "shuf viro_SraRunInfo.csv | head -n 2000 > test_runs\n",
    "\n",
    "cat header test_runs > $BATCH\n",
    "\n",
    "rm viro_SraRunInfo.csv header test_runs viro_*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terraform Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff --git a/terraform/main/main.tf b/terraform/main/main.tf\r\n",
      "index de2d00d..b3bad70 100644\r\n",
      "--- a/terraform/main/main.tf\r\n",
      "+++ b/terraform/main/main.tf\r\n",
      "@@ -12,14 +12,14 @@ variable \"aws_region\" {\r\n",
      " }\r\n",
      " \r\n",
      " variable \"dl_size\" {\r\n",
      "-  type    = number\r\n",
      "-  default = 0\r\n",
      "+  type        = number\r\n",
      "+  default     = 0\r\n",
      "   description = \"Default number of downloader nodes (ASG)\"\r\n",
      " }\r\n",
      " \r\n",
      " variable \"align_size\" {\r\n",
      "-  type    = number\r\n",
      "-  default = 0\r\n",
      "+  type        = number\r\n",
      "+  default     = 0\r\n",
      "   description = \"Default number of aligner nodes (ASG)\"\r\n",
      " }\r\n",
      " \r\n",
      "@@ -38,14 +38,22 @@ variable \"dockerhub_account\" {\r\n",
      " }\r\n",
      " \r\n",
      " variable \"scheduler_port\" {\r\n",
      "-  type  = number\r\n",
      "+  type    = number\r\n",
      "   default = 8000\r\n",
      " }\r\n",
      " \r\n",
      "+variable \"output_bucket\" {\r\n",
      "+  type = string\r\n",
      "+}\r\n",
      "+\r\n",
      "+//variable \"metrics_ip\" {\r\n",
      "+//  type = string\r\n",
      "+//}\r\n",
      "+\r\n",
      " // PROVIDER/AWS ##############################\r\n",
      " provider \"aws\" {\r\n",
      "-  version     = \"~> 2.49\"\r\n",
      "-  region      = var.aws_region\r\n",
      "+  version = \"~> 2.49\"\r\n",
      "+  region  = var.aws_region\r\n",
      " }\r\n",
      " \r\n",
      " provider \"local\" {\r\n",
      "@@ -81,67 +89,72 @@ resource \"aws_security_group\" \"internal\" {\r\n",
      " \r\n",
      " // Working S3 storage for Serratus\r\n",
      " module \"work_bucket\" {\r\n",
      "-  source   = \"../bucket\"\r\n",
      "+  source = \"../bucket\"\r\n",
      " \r\n",
      "   prefixes = [\"fq-blocks\", \"bam-blocks\", \"out\"]\r\n",
      " }\r\n",
      " \r\n",
      " // Cluster scheduler and task manager\r\n",
      " module \"scheduler\" {\r\n",
      "-  source             = \"../scheduler\"\r\n",
      "-  \r\n",
      "+  source = \"../scheduler\"\r\n",
      "+\r\n",
      "   security_group_ids = [aws_security_group.internal.id]\r\n",
      "   key_name           = var.key_name\r\n",
      "-  instance_type      = \"c5.large\"\r\n",
      "+  instance_type      = \"m5.large\"\r\n",
      "   dockerhub_account  = var.dockerhub_account\r\n",
      "   scheduler_port     = var.scheduler_port\r\n",
      "+\r\n",
      "+  //# https://wiki.postgresql.org/wiki/Tuning_Your_PostgreSQL_Server\r\n",
      "+  //pg_shared_buffers  = \"2GB\" # 1/4 of RAM\r\n",
      "+  //pg_effective_cache = \"6GB\" # 3/4 of RAM\r\n",
      " }\r\n",
      " \r\n",
      " // Cluster monitor\r\n",
      " module \"monitoring\" {\r\n",
      "-  source             = \"../monitoring\"\r\n",
      "+  source = \"../monitoring\"\r\n",
      " \r\n",
      "   security_group_ids = [aws_security_group.internal.id]\r\n",
      "   key_name           = var.key_name\r\n",
      "   scheduler_ip       = module.scheduler.private_ip\r\n",
      "+  //metrics_ip         = var.metrics_ip\r\n",
      "   dockerhub_account  = var.dockerhub_account\r\n",
      "   instance_type      = \"r5.large\"\r\n",
      " }\r\n",
      " \r\n",
      " // Serratus-dl\r\n",
      " module \"download\" {\r\n",
      "-  source             = \"../worker\"\r\n",
      "+  source = \"../worker\"\r\n",
      " \r\n",
      "-  desired_size       = 0\r\n",
      "-  max_size           = 200\r\n",
      "+  desired_size = 0\r\n",
      "+  max_size     = 5000\r\n",
      " \r\n",
      "   dev_cidrs          = var.dev_cidrs\r\n",
      "   security_group_ids = [aws_security_group.internal.id]\r\n",
      " \r\n",
      "-  instance_type      = \"r5.large\" // Mitigate the memory leak in fastq-dump\r\n",
      "-  volume_size        = 250 // Mitigate the storage leak in fastq-dump\r\n",
      "-  spot_price         = 0.10\r\n",
      "+  instance_type = \"r5.xlarge\" // Mitigate the memory leak in fastq-dump\r\n",
      "+  volume_size   = 100         // Mitigate the storage leak in fastq-dump\r\n",
      "+  spot_price    = 0.10\r\n",
      " \r\n",
      "-  s3_bucket          = module.work_bucket.name\r\n",
      "-  s3_prefix          = \"fq-blocks\"\r\n",
      "+  s3_bucket = module.work_bucket.name\r\n",
      "+  s3_prefix = \"fq-blocks\"\r\n",
      " \r\n",
      "-  image_name         = \"serratus-dl\"\r\n",
      "-  dockerhub_account  = var.dockerhub_account\r\n",
      "-  key_name           = var.key_name\r\n",
      "-  scheduler          = \"${module.scheduler.public_dns}:${var.scheduler_port}\"\r\n",
      "-  options            = \"-k ${module.work_bucket.name}\"\r\n",
      "+  image_name        = \"serratus-dl\"\r\n",
      "+  dockerhub_account = var.dockerhub_account\r\n",
      "+  key_name          = var.key_name\r\n",
      "+  scheduler         = \"${module.scheduler.public_dns}:${var.scheduler_port}\"\r\n",
      "+  options           = \"-k ${module.work_bucket.name}\"\r\n",
      " }\r\n",
      " \r\n",
      " // Serratus-align\r\n",
      " module \"align\" {\r\n",
      "-  source             = \"../worker\"\r\n",
      "+  source = \"../worker\"\r\n",
      " \r\n",
      "   desired_size       = 0\r\n",
      "-  max_size           = 500\r\n",
      "+  max_size           = 10000\r\n",
      "   dev_cidrs          = var.dev_cidrs\r\n",
      "   security_group_ids = [aws_security_group.internal.id]\r\n",
      "-  instance_type      = \"c5.large\" # c5.large\r\n",
      "-  volume_size        = 10\r\n",
      "+  instance_type      = \"c5.xlarge\" # c5.large\r\n",
      "+  volume_size        = 12\r\n",
      "   spot_price         = 0.10\r\n",
      "   s3_bucket          = module.work_bucket.name\r\n",
      "   s3_delete_prefix   = \"fq-blocks\"\r\n",
      "@@ -150,12 +163,12 @@ module \"align\" {\r\n",
      "   image_name         = \"serratus-align\"\r\n",
      "   key_name           = var.key_name\r\n",
      "   scheduler          = \"${module.scheduler.public_dns}:${var.scheduler_port}\"\r\n",
      "-  options            = \"-k ${module.work_bucket.name} -a bowtie2\"\r\n",
      "+  options            = \"-k ${module.work_bucket.name} -a diamond\"\r\n",
      " }\r\n",
      " \r\n",
      " //Serratus-merge\r\n",
      " module \"merge\" {\r\n",
      "-  source             = \"../worker\"\r\n",
      "+  source = \"../worker\"\r\n",
      " \r\n",
      "   desired_size       = 0\r\n",
      "   max_size           = 50\r\n",
      "@@ -165,36 +178,31 @@ module \"merge\" {\r\n",
      "   volume_size        = 150 // prevent disk overflow via samtools cat\r\n",
      "   spot_price         = 0.05\r\n",
      "   s3_bucket          = module.work_bucket.name\r\n",
      "-  // TODO: Add delete permissions for *-blocks\r\n",
      "-  // to merge as redundant delete of completed data\r\n",
      "-  s3_delete_prefix   = \"bam-blocks\"\r\n",
      "-  s3_prefix          = \"out\"\r\n",
      "-  dockerhub_account  = var.dockerhub_account\r\n",
      "-  image_name         = \"serratus-merge\"\r\n",
      "-  key_name           = var.key_name\r\n",
      "-  scheduler          = \"${module.scheduler.public_dns}:${var.scheduler_port}\"\r\n",
      "-  // TODO: the credentials are not properly set-up to\r\n",
      "-  //       upload to serratus-public, requires a *Object policy\r\n",
      "-  //       on the bucket.\r\n",
      "-  options            = \"-k ${module.work_bucket.name} -b ${var.output_bucket}\"\r\n",
      "+  s3_delete_prefix  = \"bam-blocks\"\r\n",
      "+  s3_prefix         = \"out\"\r\n",
      "+  dockerhub_account = var.dockerhub_account\r\n",
      "+  image_name        = \"serratus-merge\"\r\n",
      "+  key_name          = var.key_name\r\n",
      "+  scheduler         = \"${module.scheduler.public_dns}:${var.scheduler_port}\"\r\n",
      "+  options = \"-k ${module.work_bucket.name} -b s3://serratus-public/out/200830_test\"\r\n",
      " }\r\n",
      " \r\n",
      " // RESOURCES ##############################\r\n",
      " // Controller scripts created locally\r\n",
      " \r\n",
      " resource \"local_file\" \"hosts\" {\r\n",
      "-  filename = \"${path.module}/serratus-hosts\"\r\n",
      "+  filename        = \"${path.module}/serratus-hosts\"\r\n",
      "   file_permission = 0666\r\n",
      "-  content = <<-EOF\r\n",
      "+  content         = <<-EOF\r\n",
      "     aws_monitor ${module.monitoring.public_dns}\r\n",
      "     aws_scheduler ${module.scheduler.public_dns}\r\n",
      "   EOF\r\n",
      " }\r\n",
      " \r\n",
      " resource \"local_file\" \"create_tunnel\" {\r\n",
      "-  filename = \"${path.module}/create_tunnels.sh\"\r\n",
      "+  filename        = \"${path.module}/create_tunnels.sh\"\r\n",
      "   file_permission = 0777\r\n",
      "-  content = <<-EOF\r\n",
      "+  content         = <<-EOF\r\n",
      "     #!/bin/bash\r\n",
      "     set -eu\r\n",
      "     ssh -Nf -L 3000:localhost:3000 -L 9090:localhost:9090 ec2-user@${module.monitoring.public_dns}\r\n",
      "@@ -208,9 +216,9 @@ resource \"local_file\" \"create_tunnel\" {\r\n",
      " }\r\n",
      " \r\n",
      " resource \"local_file\" \"upload_sra\" {\r\n",
      "-  filename = \"${path.module}/uploadSRA.sh\"\r\n",
      "+  filename        = \"${path.module}/uploadSRA.sh\"\r\n",
      "   file_permission = 0777\r\n",
      "-  content = <<-EOF\r\n",
      "+  content         = <<-EOF\r\n",
      "     #!/bin/bash\r\n",
      "     # =====================================\r\n",
      "     # Serratus - uploadSRA.sh\r\n",
      "@@ -289,7 +297,6 @@ resource \"local_file\" \"upload_sra\" {\r\n",
      "   EOF\r\n",
      " }\r\n",
      " \r\n",
      "-\r\n",
      " // OUTPUT ##############################\r\n",
      " output \"help\" {\r\n",
      "   value = <<-EOF\r\n",
      "\u001b[0m\u001b[1mInitializing modules...\u001b[0m\r\n",
      "\r\n",
      "\u001b[0m\u001b[1mInitializing the backend...\u001b[0m\r\n",
      "\r\n",
      "\u001b[0m\u001b[1mInitializing provider plugins...\u001b[0m\r\n",
      "\r\n",
      "The following providers do not have any version constraints in configuration,\r\n",
      "so the latest version was installed.\r\n",
      "\r\n",
      "To prevent automatic upgrades to new major versions that may contain breaking\r\n",
      "changes, it is recommended to add version = \"...\" constraints to the\r\n",
      "corresponding provider blocks in configuration, with the constraint strings\r\n",
      "suggested below.\r\n",
      "\r\n",
      "* provider.random: version = \"~> 2.2\"\r\n",
      "\r\n",
      "\u001b[0m\u001b[1m\u001b[32mTerraform has been successfully initialized!\u001b[0m\u001b[32m\u001b[0m\r\n",
      "\u001b[0m\u001b[32m\r\n",
      "You may now begin working with Terraform. Try running \"terraform plan\" to see\r\n",
      "any changes that are required for your infrastructure. All Terraform commands\r\n",
      "should now work.\r\n",
      "\r\n",
      "If you ever set or change modules or backend configuration for Terraform,\r\n",
      "rerun this command to reinitialize your working directory. If you forget, other\r\n",
      "commands will detect it and remind you to do so if necessary.\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.data.aws_availability_zones.all: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.data.aws_region.current: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.data.aws_ami.amazon_linux_2: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.data.aws_ami.amazon_linux_2: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.data.aws_region.current: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.data.aws_region.current: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.data.aws_region.current: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.data.aws_availability_zones.all: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.data.aws_availability_zones.all: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.data.aws_ami.amazon_linux_2: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.data.aws_ami.ecs: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.data.aws_ami.ecs: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.data.aws_ami.amazon_linux_2: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.data.aws_region.current: Refreshing state...\u001b[0m\r\n",
      "\u001b[0m\u001b[1mlocal_file.upload_sra: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mlocal_file.upload_sra: Creation complete after 0s [id=db5deb3269742410535713cc6c7c3d53cbb21cfe]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.random_password.pg_password: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.random_password.pg_password: Creation complete after 0s [id=none]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_cloudwatch_log_group.g: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_cloudwatch_log_group.scheduler: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_role.task_role: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_ecs_cluster.c: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_cloudwatch_log_group.g: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_role.task_role: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_cloudwatch_log_group.g: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_role.instance_role: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_ecs_cluster.c: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket.work: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_role.instance_role: Creation complete after 1s [id=SerratusEcsInstanceRole-monitor]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_role.task_role: Creation complete after 1s [id=SerratusIamRole-monitor]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role.role: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_role.instance_role: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_role.task_role: Creation complete after 1s [id=SerratusIamRole-scheduler]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role.role: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_cloudwatch_log_group.scheduler: Creation complete after 1s [id=serratus-scheduler]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role.role: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_cloudwatch_log_group.g: Creation complete after 2s [id=serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1maws_security_group.internal: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role.role: Creation complete after 1s [id=SerratusIamRole-serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_cloudwatch_log_group.g: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_role.instance_role: Creation complete after 1s [id=SerratusEcsInstanceRole-scheduler]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role.role: Creation complete after 1s [id=SerratusIamRole-serratus-dl]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_instance_profile.p: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_role_policy_attachment.instance_attachment: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role.role: Creation complete after 0s [id=SerratusIamRole-serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_instance_profile.profile: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_cloudwatch_log_group.g: Creation complete after 3s [id=serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role_policy.cloudwatch: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_cloudwatch_log_group.g: Creation complete after 3s [id=serratus-monitor]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_role_policy_attachment.instance_attachment: Creation complete after 1s [id=SerratusEcsInstanceRole-monitor-20200830172017537500000002]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_role_policy_attachment.instance_attachment: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_cloudwatch_log_group.g: Creation complete after 1s [id=serratus-dl]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_instance_profile.p: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_iam_instance_profile.p: Creation complete after 1s [id=instance-profile-serratus-monitor]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_instance_profile.profile: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role_policy.cloudwatch: Creation complete after 0s [id=SerratusIamRole-serratus-align:CloudWatchLogsCreate-serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_instance_profile.profile: Creation complete after 1s [id=profile-serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role_policy.cloudwatch: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creation complete after 1s [id=SerratusIamRole-serratus-align-20200830172018203700000003]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_role_policy_attachment.instance_attachment: Creation complete after 1s [id=SerratusEcsInstanceRole-scheduler-20200830172018301700000004]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_instance_profile.profile: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creation complete after 0s [id=SerratusIamRole-serratus-dl-20200830172018920700000005]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_role_policy.cloudwatch: Creation complete after 0s [id=SerratusIamRole-serratus-dl:CloudWatchLogsCreate-serratus-dl]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role_policy.cloudwatch: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role_policy_attachment.attachment: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_iam_instance_profile.p: Creation complete after 1s [id=instance-profile-serratus-scheduler]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_ecs_task_definition.scheduler: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role_policy_attachment.attachment[\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"]: Creation complete after 0s [id=SerratusIamRole-serratus-merge-20200830172019009100000006]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_iam_role_policy.scheduler: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.module.iam_role.aws_iam_instance_profile.profile: Creation complete after 2s [id=profile-serratus-dl]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role_policy.cloudwatch: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_instance_profile.profile: Creation complete after 1s [id=profile-serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.ec2Describe: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role_policy_attachment.attachment: Creation complete after 1s [id=SerratusIamRole-monitor-20200830172019737400000007]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.ec2Terminate: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.module.iam_role.aws_iam_role_policy.cloudwatch: Creation complete after 1s [id=SerratusIamRole-serratus-merge:CloudWatchLogsCreate-serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.AdjustAutoScaling: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_ecs_task_definition.scheduler: Creation complete after 1s [id=scheduler]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.ec2Describe: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_iam_role_policy.scheduler: Creation complete after 1s [id=SerratusIamRole-scheduler:DescribeInstances-scheduler]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.AdjustAutoScaling: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_iam_role_policy.cloudwatch: Creation complete after 0s [id=SerratusIamRole-monitor:CloudwatchGetMetrics]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.ec2Terminate: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.ec2Describe: Creation complete after 1s [id=SerratusIamRole-serratus-align:DescribeEC2Instances-serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.ec2Describe: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1maws_security_group.internal: Creation complete after 4s [id=sg-0946a8ec22f365979]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.ec2Terminate: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.AdjustAutoScaling: Creation complete after 1s [id=SerratusIamRole-serratus-align:AdjustAutoScaling-serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.ec2Terminate: Creation complete after 1s [id=SerratusIamRole-serratus-align:TerminateEC2Instances-serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.AdjustAutoScaling: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.ec2Describe: Creation complete after 1s [id=SerratusIamRole-serratus-dl:DescribeEC2Instances-serratus-dl]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.AdjustAutoScaling: Creation complete after 1s [id=SerratusIamRole-serratus-dl:AdjustAutoScaling-serratus-dl]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.ec2Terminate: Creation complete after 1s [id=SerratusIamRole-serratus-dl:TerminateEC2Instances-serratus-dl]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.ec2Describe: Creation complete after 0s [id=SerratusIamRole-serratus-merge:DescribeEC2Instances-serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.AdjustAutoScaling: Creation complete after 1s [id=SerratusIamRole-serratus-merge:AdjustAutoScaling-serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.ec2Terminate: Creation complete after 1s [id=SerratusIamRole-serratus-merge:TerminateEC2Instances-serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket.work: Creation complete after 7s [id=tf-serratus-work-20200830172015348800000001]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.full: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"fq-blocks\"]: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.s3_write: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"bam-blocks\"]: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"out\"]: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.s3_delete[0]: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.s3_delete[0]: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.s3_write: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.full: Creation complete after 1s [id=tf-serratus-work-20200830172015348800000001:full]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"bam-blocks\"]: Creation complete after 1s [id=tf-serratus-work-20200830172015348800000001:prefix-bam-blocks]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"fq-blocks\"]: Creation complete after 1s [id=tf-serratus-work-20200830172015348800000001:prefix-fq-blocks]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.s3_delete[0]: Creation complete after 1s [id=SerratusIamRole-serratus-align:S3DeleteData-serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.s3_write: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_iam_role_policy.s3_write: Creation complete after 1s [id=SerratusIamRole-serratus-dl:S3WriteData-serratus-dl]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.work_bucket.aws_s3_bucket_metric.prefix[\"out\"]: Creation complete after 1s [id=tf-serratus-work-20200830172015348800000001:prefix-out]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.s3_write: Creation complete after 1s [id=SerratusIamRole-serratus-merge:S3WriteData-serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_iam_role_policy.s3_delete[0]: Creation complete after 1s [id=SerratusIamRole-serratus-merge:S3DeleteData-serratus-merge]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_iam_role_policy.s3_write: Creation complete after 1s [id=SerratusIamRole-serratus-align:S3WriteData-serratus-align]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_ecs_cluster.c: Still creating... [10s elapsed]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_ecs_cluster.c: Still creating... [10s elapsed]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_ecs_cluster.c: Creation complete after 12s [id=arn:aws:ecs:us-east-1:797308887321:cluster/serratus-scheduler]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_ecs_cluster.c: Creation complete after 12s [id=arn:aws:ecs:us-east-1:797308887321:cluster/serratus-monitor]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_ecs_service.scheduler: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_instance.i: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_instance.i: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_ecs_service.scheduler: Creation complete after 1s [id=arn:aws:ecs:us-east-1:797308887321:service/serratus-scheduler]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_instance.i: Still creating... [10s elapsed]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_instance.i: Still creating... [10s elapsed]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.module.ecs_cluster.aws_instance.i: Creation complete after 16s [id=i-09b00ab2fa2b3ee2a]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_eip.monitor: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.module.ecs_cluster.aws_instance.i: Creation complete after 16s [id=i-04e3a76c0e05e90e3]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_eip.sch: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_ecs_task_definition.monitor: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_ecs_task_definition.monitor: Creation complete after 1s [id=monitor]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_ecs_service.monitor: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_ecs_service.monitor: Creation complete after 1s [id=arn:aws:ecs:us-east-1:797308887321:service/serratus-monitor]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.scheduler.aws_eip.sch: Creation complete after 3s [id=eipalloc-0ed173d6973dbafe6]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_launch_configuration.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_launch_configuration.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_launch_configuration.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.monitoring.aws_eip.monitor: Creation complete after 3s [id=eipalloc-0658bc4202a152ef5]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mlocal_file.hosts: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mlocal_file.create_tunnel: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mlocal_file.hosts: Creation complete after 0s [id=6fb8946c8f92d5fcef987d58088b63d6a64d8f70]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mlocal_file.create_tunnel: Creation complete after 0s [id=79cfe2358cafd13a0caf3788d1c3ce5dfeb71719]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_launch_configuration.worker: Creation complete after 2s [id=serratus-merge-2020083017204651520000000a]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_launch_configuration.worker: Creation complete after 2s [id=serratus-align-2020083017204652140000000c]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_autoscaling_group.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_launch_configuration.worker: Creation complete after 2s [id=serratus-dl-2020083017204651520000000b]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_autoscaling_group.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_autoscaling_group.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_autoscaling_group.worker: Creation complete after 1s [id=serratus-merge-2020083017204651520000000a]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_autoscaling_policy.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_autoscaling_group.worker: Creation complete after 1s [id=serratus-dl-2020083017204651520000000b]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_autoscaling_group.worker: Creation complete after 1s [id=serratus-align-2020083017204652140000000c]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_autoscaling_policy.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_autoscaling_policy.worker: Creating...\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.merge.aws_autoscaling_policy.worker: Creation complete after 1s [id=serratus-merge-2020083017204651520000000a]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.align.aws_autoscaling_policy.worker: Creation complete after 0s [id=serratus-align-2020083017204652140000000c]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1mmodule.download.aws_autoscaling_policy.worker: Creation complete after 0s [id=serratus-dl-2020083017204651520000000b]\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1m\u001b[32m\r\n",
      "Apply complete! Resources: 71 added, 0 changed, 0 destroyed.\u001b[0m\r\n",
      "\u001b[0m\u001b[1m\u001b[32m\r\n",
      "Outputs:\r\n",
      "\r\n",
      "align_asg_name = serratus-align-2020083017204652140000000c\r\n",
      "dl_asg_name = serratus-dl-2020083017204651520000000b\r\n",
      "help = Run ./create_tunnels.sh to create SSH tunnels for all services.\r\n",
      "\r\n",
      "merge_asg_name = serratus-merge-2020083017204651520000000a\r\n",
      "monitor_dns = ec2-18-205-138-128.compute-1.amazonaws.com\r\n",
      "scheduler_dns = ec2-54-90-5-95.compute-1.amazonaws.com\r\n",
      "scheduler_pg_password = etVCHSCK7TBaDRkG\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# For rapid batching; copy out serratus folder\n",
    "# PROTEIN / DNA MUST BE SET IN CONFIG FILE\n",
    "# LINE 153\n",
    "#   options            = \"-k ${module.work_bucket.name} -a bowtie2\"\n",
    "#   options            = \"-k ${module.work_bucket.name} -a diamond\"\n",
    "\n",
    "TF=$SERRATUS/terraform/main\n",
    "cd $TF\n",
    "git diff main.tf\n",
    "terraform init\n",
    "\n",
    "# Launch Terraform Cluster\n",
    "# Initialize the serratus cluster with minimal nodes\n",
    "terraform apply -auto-approve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Permanently added 'ec2-18-205-138-128.compute-1.amazonaws.com,18.205.138.128' (ECDSA) to the list of known hosts.\r",
      "\r\n",
      "Warning: Permanently added 'ec2-54-90-5-95.compute-1.amazonaws.com,54.90.5.95' (ECDSA) to the list of known hosts.\r",
      "\r\n",
      "Tunnels created:\r\n",
      "    localhost:3000 = grafana\r\n",
      "    localhost:9090 = prometheus\r\n",
      "    localhost:5432 = postgres\r\n",
      "    localhost:8000 = scheduler\r\n"
     ]
    }
   ],
   "source": [
    "cd $TF\n",
    "\n",
    "# Open SSH tunnels to the monitor\n",
    "./create_tunnels.sh\n",
    "\n",
    "# If you get an error on port\n",
    "# run:\n",
    "# ps aux | grep ssh\n",
    "# sudo kill <PID of SSH>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001 /home/artem/serratus/notebook/200822_ab/test2_SraRunInfo.csv\r\n"
     ]
    }
   ],
   "source": [
    "cd $WORK\n",
    "BATCH='test2_SraRunInfo.csv'\n",
    "wc -l $WORK/$BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SRARunInfo into scheduler \r\n",
      "  File: /home/artem/serratus/notebook/200822_ab/test2_SraRunInfo.csv\r\n",
      "  date: Sun Aug 30 10:26:34 PDT 2020\r\n",
      "  wc  : 1001 /home/artem/serratus/notebook/200822_ab/test2_SraRunInfo.csv\r\n",
      "  md5 : 88bd753808099efbd48f58666a9e51c3  /home/artem/serratus/notebook/200822_ab/test2_SraRunInfo.csv\r\n",
      "\r\n",
      "\r\n",
      "--------------------------\r\n",
      "tmp.chunk00\r\n",
      "1001 tmp.chunk00_sraRunInfo.csv\r\n",
      "459076ff46b172c8515efd6721a9f50b  tmp.chunk00_sraRunInfo.csv\r\n",
      "{\"inserted_rows\":1000,\"total_rows\":1000}\r\n",
      "\r\n",
      "\r\n",
      " uploadSRA complete.\r\n"
     ]
    }
   ],
   "source": [
    "# Upload SraRunInfo.csv into Serratus\n",
    "cd $TF\n",
    "./uploadSRA.sh $WORK/$BATCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Serratus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Cluster Config File: \r\n",
      "{\r\n",
      "  \"ALIGN_ARGS\": \"--very-sensitive-local\",\r\n",
      "  \"ALIGN_MAX_INCREASE\": 25,\r\n",
      "  \"ALIGN_SCALING_CONSTANT\": 0.05,\r\n",
      "  \"ALIGN_SCALING_ENABLE\": true,\r\n",
      "  \"ALIGN_SCALING_MAX\": 1000,\r\n",
      "  \"CLEAR_INTERVAL\": 600,\r\n",
      "  \"DL_ARGS\": \"\",\r\n",
      "  \"DL_MAX_INCREASE\": 10,\r\n",
      "  \"DL_SCALING_CONSTANT\": 0.1,\r\n",
      "  \"DL_SCALING_ENABLE\": true,\r\n",
      "  \"DL_SCALING_MAX\": 250,\r\n",
      "  \"GENOME\": \"protref5\",\r\n",
      "  \"MERGE_ARGS\": \"protein\",\r\n",
      "  \"MERGE_MAX_INCREASE\": 5,\r\n",
      "  \"MERGE_SCALING_CONSTANT\": 0.1,\r\n",
      "  \"MERGE_SCALING_ENABLE\": true,\r\n",
      "  \"MERGE_SCALING_MAX\": 15,\r\n",
      "  \"SCALING_INTERVAL\": 120,\r\n",
      "  \"VIRTUAL_SCALING_INTERVAL\": 45\r\n",
      "}\r\n",
      "\r\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0{\"ALIGN_ARGS\":\"--very-sensitive-local\",\"ALIGN_MAX_INCREASE\":25,\"ALIGN_SCALING_CONSTANT\":0.05,\"ALIGN_SCALING_ENABLE\":true,\"ALIGN_SCALING_MAX\":1000,\"CLEAR_INTERVAL\":600,\"DL_ARGS\":\"\",\"DL_MAX_INCREASE\":10,\"DL_SCALING_CONSTANT\":0.1,\"DL_SCALING_ENABLE\":true,\"DL_SCALING_MAX\":250,\"GENOME\":\"protref5\",\"MERGE_ARGS\":\"protein\",\"MERGE_MAX_INCREASE\":5,\"MERGE_SCALING_CONSTANT\":0.1,\"MERGE_SCALING_ENABLE\":true,\"MERGE_SCALING_MAX\":15,\"SCALING_INTERVAL\":120,\"VIRTUAL_SCALING_INTERVAL\":45}\r\n",
      "\r",
      "100  1022  100   473  100   549    555    645 --:--:-- --:--:-- --:--:--  1200\r\n"
     ]
    }
   ],
   "source": [
    "# Set Cluster Parameters =============================\n",
    "## get Config File (if it doesn't exist)\n",
    "# curl localhost:8000/config | jq > serratus-config.json\n",
    "\n",
    "cd $TF\n",
    "# Make local changes to config file\n",
    "echo \"  Cluster Config File: \"\n",
    "cat serratus-config.json\n",
    "echo \"\"\n",
    "echo \"\"\n",
    "# Re-upload config file\n",
    "curl -T serratus-config.json localhost:8000/config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stop postgres if it's running \n",
    "# systemctl stop postgresql\n",
    "\n",
    "## Connect to postgres\n",
    "# psql -h localhost postgres postgres\n",
    "\n",
    "#  psql -h localhost postgres postgres -c \"DELETE FROM blocks WHERE state = 'done';\"\n",
    "\n",
    "### ACCESSION OPERATIONS\n",
    "## Reset SPLITTING accessions to NEW\n",
    "# UPDATE acc SET state = 'new' WHERE state = 'splitting';\n",
    "\n",
    "## Reset SPLIT_ERR accessions to NEW\n",
    "## (repeated failures can be missing SRA data)\n",
    "# UPDATE acc SET state = 'new' WHERE state = 'split_err';\n",
    "\n",
    "## Reset MERGE_ERR accessions to SPLIT_DONE\n",
    "# UPDATE acc SET state = 'split_done' WHERE state = 'merge_err';\n",
    "\n",
    "## Clear DONE Accessions (ONLY ON COMPLETION)\n",
    "# DELETE FROM acc WHERE state = 'merge_done';\n",
    "\n",
    "### BLOCK OPERATIONS\n",
    "\n",
    "##  Reset FAIL blocks to NEW\n",
    "# UPDATE blocks SET state = 'new' WHERE state = 'fail';\n",
    "\n",
    "# Reset ALIGNING blocks to NEW\n",
    "# UPDATE blocks SET state = 'new' WHERE state = 'aligning';\n",
    "\n",
    "# Clear Done\n",
    "# DELETE FROM blocks WHERE state = 'done';\n",
    "\n",
    "# RESET STATE\n",
    "# DELETE FROM blocks WHERE state = 'done';\n",
    "# DELETE FROM blocks WHERE state = 'fail';\n",
    "#\n",
    "#\n",
    "# DELETE FROM acc WHERE state = 'split_err';\n",
    "# DELETE FROM acc WHERE state = 'merging';\n",
    "# DELETE FROM acc WHERE state = 'merge_err';\n",
    "# DELETE FROM acc WHERE state = 'split_done';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuke Shutdown\n",
    "aws ec2 describe-instances \\\n",
    "  --filter Name=tag:Name,Values=serratus-align-instance \\\n",
    "  > align_instances.json\n",
    "\n",
    "jq '.Reservations[].Instances[].InstanceId' -r align_instances.json \\\n",
    "  | pv -l \\\n",
    "  | xargs -n10 -P10 aws ec2 terminate-instances --instance-ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UPDATE TO PROTREF CAME THROUGH\n",
    "# SHUTTING DOWN AND RESTARTING AFTER 34K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring sumbler data\n",
    "# DO NOT UNCOMMENT WILL DELETE MANY FILES\n",
    "# aws s3 sync s3://serratus-public/out/200823_test/sumbler/ ./\n",
    "# find . -size -2k -exec rm '{}' \\;\n",
    "# grep 'SRAsum' * | sed 's/;/\\t  /g' -"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
